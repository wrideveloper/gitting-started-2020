{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-in-tfjs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlB-hzwlFuCm",
        "colab_type": "text"
      },
      "source": [
        "# **binary classification dataset https://www.kaggle.com/marklvl/sentiment-labelled-sentences-data-set?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRCq_4QZdQV0",
        "colab_type": "text"
      },
      "source": [
        "Untuk mendownload data menggunakan API Kaggle, buat akun Kaggle. Pada kanan atas klik My Profile > Account pada titik tiga > API > Create API Account. Copykan Username & Key pada kode di bawah"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHyzoam_bFqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = #UBAH DENGAN USERNAME ANDA\n",
        "os.environ['KAGGLE_KEY'] = #UBAH DENGAN PASSWORD ANDA"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibA66bBbbV8t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8e50e329-1af6-46b1-eb9e-370b43a1701e"
      },
      "source": [
        "!kaggle datasets download -d marklvl/sentiment-labelled-sentences-data-set"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading sentiment-labelled-sentences-data-set.zip to /content\n",
            "\r  0% 0.00/326k [00:00<?, ?B/s]\n",
            "\r100% 326k/326k [00:00<00:00, 48.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibtSBe31b34m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q sentiment-labelled-sentences-data-set.zip -d ."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVNVV-MSM69Z",
        "colab_type": "text"
      },
      "source": [
        "## **LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTwy9t-hM-ua",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0c8831d-138b-4193-ce59-58439d9879ee"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "df = pd.read_csv('/content/sentiment labelled sentences/yelp_labelled.txt', names=['sentence', 'label'], sep='\\t')\n",
        "df.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cofl6pB8lHFo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "d5f0aa96-ea30-4532-888a-84d18b2c2781"
      },
      "source": [
        "df.head"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                               sentence  label\n",
              "0                             Wow... Loved this place.      1\n",
              "1                                   Crust is not good.      0\n",
              "2            Not tasty and the texture was just nasty.      0\n",
              "3    Stopped by during the late May bank holiday of...      1\n",
              "4    The selection on the menu was great and so wer...      1\n",
              "..                                                 ...    ...\n",
              "995  I think food should have flavor and texture an...      0\n",
              "996                           Appetite instantly gone.      0\n",
              "997  Overall I was not impressed and would not go b...      0\n",
              "998  The whole experience was underwhelming, and I ...      0\n",
              "999  Then, as if I hadn't wasted enough of my life ...      0\n",
              "\n",
              "[1000 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDue0G_drWAl",
        "colab_type": "text"
      },
      "source": [
        "Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T7jl8UVrXo2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert to lowercase\n",
        "df['sentence'] = df['sentence'].str.lower()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOy-ylB1rfd4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9b5c732d-d4b8-440c-e873-da1507e30ede"
      },
      "source": [
        "# remove stopwords\n",
        "\n",
        "#from nltk.corpus import stopwords #comment jika Error dan gunakan 2 sintaks dibawah\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srwk40Vqcazy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "cea0c6c6-d085-4b27-c044-04b23e01415e"
      },
      "source": [
        "\n",
        "stop = set(stopwords.words('english'))\n",
        "df['sentence'] = df['sentence'].apply(lambda x:' '.join([word for word in x.split() if word not in (stop)]))\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wow... loved place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>crust good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tasty texture nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>stopped late may bank holiday rick steve recom...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>selection menu great prices.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label\n",
              "0                                wow... loved place.      1\n",
              "1                                        crust good.      0\n",
              "2                               tasty texture nasty.      0\n",
              "3  stopped late may bank holiday rick steve recom...      1\n",
              "4                       selection menu great prices.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-lnuvqQrtUz",
        "colab_type": "text"
      },
      "source": [
        "Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMjLCJclrsYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "11dfc11b-e70c-4d42-8ebd-ed6247d20eeb"
      },
      "source": [
        "vocab_size = 2000\n",
        "oov_tok = \"<OOV>\"\n",
        "filt = '!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~ ' #remove symbols\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = vocab_size, oov_token = oov_tok, filters = filt)\n",
        "tokenizer.fit_on_texts(df['sentence'].values)\n",
        "\n",
        "word2index = tokenizer.word_index\n",
        "print(len(word2index))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whWt0LYxvO-C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "with open('word2index.json', 'w') as fp:\n",
        "    json.dump(word2index, fp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ugC89x8r4La",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "954a4070-8a2a-4f05-eeda-6a483e8cdc6a"
      },
      "source": [
        "max_length =  max(len(values.split()) for i, values in enumerate(df['sentence']))\n",
        "max_length"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkoanBtWr-Fq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2ea8f7b2-9e0b-4440-ab3c-c85e4500d42a"
      },
      "source": [
        "trunc_type='post'\n",
        "\n",
        "all_seq = tokenizer.texts_to_sequences(df['sentence'].values)\n",
        "all_padded = pad_sequences(all_seq, maxlen = max_length, padding = trunc_type)\n",
        "all_padded.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 18)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSevKaW8rE2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "18368381-7ae5-4bb5-9df1-9cbbe0151656"
      },
      "source": [
        "# split train and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = all_padded\n",
        "#y = pd.get_dummies(df['label'].values)\n",
        "y = df['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=42)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)\n",
        "\n",
        "#kalimat = df['sentence'].values\n",
        "#y = df['label'].values\n",
        "\n",
        "#kalimat_latih, kalimat_test, y_latih, y_test = train_test_split(kalimat, y, \n",
        "#                                                                test_size=0.2, random_state=1000)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(800, 18) (800,)\n",
            "(200, 18) (200,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUwJnNOZNp5K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1732c25f-14f5-45cd-df8d-00fb340a1c34"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim= vocab_size, output_dim=16, input_length= max_length),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(24, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 18, 16)            32000     \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 64)                20736     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 24)                1560      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 25        \n",
            "=================================================================\n",
            "Total params: 54,321\n",
            "Trainable params: 54,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbI-o4_TNvbH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fddad869-60cc-4c19-c487-a9d46808dc62"
      },
      "source": [
        "num_epochs = 30\n",
        "history = model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "25/25 [==============================] - 1s 32ms/step - loss: 0.6940 - accuracy: 0.5050 - val_loss: 0.6935 - val_accuracy: 0.4800\n",
            "Epoch 2/30\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.6935 - accuracy: 0.5050 - val_loss: 0.6940 - val_accuracy: 0.4800\n",
            "Epoch 3/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.6898 - accuracy: 0.5512 - val_loss: 0.6826 - val_accuracy: 0.6200\n",
            "Epoch 4/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.4202 - accuracy: 0.8712 - val_loss: 0.7980 - val_accuracy: 0.7300\n",
            "Epoch 5/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.1931 - accuracy: 0.9425 - val_loss: 0.6945 - val_accuracy: 0.7100\n",
            "Epoch 6/30\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.1073 - accuracy: 0.9737 - val_loss: 0.8187 - val_accuracy: 0.7600\n",
            "Epoch 7/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0490 - accuracy: 0.9875 - val_loss: 0.8381 - val_accuracy: 0.7600\n",
            "Epoch 8/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0283 - accuracy: 0.9937 - val_loss: 1.0049 - val_accuracy: 0.7450\n",
            "Epoch 9/30\n",
            "25/25 [==============================] - 0s 10ms/step - loss: 0.0152 - accuracy: 0.9950 - val_loss: 1.2625 - val_accuracy: 0.7500\n",
            "Epoch 10/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0244 - accuracy: 0.9950 - val_loss: 1.0899 - val_accuracy: 0.7650\n",
            "Epoch 11/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0105 - accuracy: 0.9987 - val_loss: 1.1273 - val_accuracy: 0.7600\n",
            "Epoch 12/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0090 - accuracy: 0.9987 - val_loss: 1.2877 - val_accuracy: 0.7650\n",
            "Epoch 13/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0127 - accuracy: 0.9975 - val_loss: 1.2627 - val_accuracy: 0.7650\n",
            "Epoch 14/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0091 - accuracy: 0.9987 - val_loss: 1.2610 - val_accuracy: 0.7650\n",
            "Epoch 15/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 1.4260 - val_accuracy: 0.7400\n",
            "Epoch 16/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0184 - accuracy: 0.9937 - val_loss: 1.3795 - val_accuracy: 0.7050\n",
            "Epoch 17/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0166 - accuracy: 0.9937 - val_loss: 1.6073 - val_accuracy: 0.7150\n",
            "Epoch 18/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0340 - accuracy: 0.9937 - val_loss: 1.1611 - val_accuracy: 0.7600\n",
            "Epoch 19/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0167 - accuracy: 0.9962 - val_loss: 1.0975 - val_accuracy: 0.7400\n",
            "Epoch 20/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0082 - accuracy: 0.9987 - val_loss: 1.3981 - val_accuracy: 0.7500\n",
            "Epoch 21/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0049 - accuracy: 0.9962 - val_loss: 1.4141 - val_accuracy: 0.7400\n",
            "Epoch 22/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 0.9987 - val_loss: 1.5318 - val_accuracy: 0.7600\n",
            "Epoch 23/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 1.4985 - val_accuracy: 0.7400\n",
            "Epoch 24/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 1.5696 - val_accuracy: 0.7450\n",
            "Epoch 25/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0138 - accuracy: 0.9962 - val_loss: 1.1777 - val_accuracy: 0.7400\n",
            "Epoch 26/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0044 - accuracy: 0.9975 - val_loss: 1.5076 - val_accuracy: 0.7450\n",
            "Epoch 27/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 1.5350 - val_accuracy: 0.7250\n",
            "Epoch 28/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0032 - accuracy: 0.9987 - val_loss: 1.3262 - val_accuracy: 0.7400\n",
            "Epoch 29/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.4571 - val_accuracy: 0.7500\n",
            "Epoch 30/30\n",
            "25/25 [==============================] - 0s 9ms/step - loss: 7.0382e-04 - accuracy: 1.0000 - val_loss: 1.5813 - val_accuracy: 0.7450\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdJLOUkoMtF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#def toSequence(sentence):\n",
        "#  pad = []\n",
        "#  for stc in sentence.split():\n",
        "#    if stc.lower() in word2index.keys(): \n",
        "#      pad.append(word2index[stc.lower()])\n",
        "#    else: \n",
        "#      continue\n",
        "#  return pad\n",
        "\n",
        "#pad = toSequence('affordable price and nice dessert')\n",
        "#pad = [269, 353, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0 ,0,0,0,0]\n",
        "#len(pad)\n",
        "#model.predict([pad])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-fp_i2PGt4J",
        "colab_type": "text"
      },
      "source": [
        "Save Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsTz_o4zGnWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "845cf853-7e60-4c51-eb40-12e964ad6761"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/4c/79739ad8652e4f0372ddfa272d4fa3bfb0497460bc319e3758e907586540/tensorflowjs-2.3.0-py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.10.0)\n",
            "Collecting tensorflow-cpu<3,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/f6/b2996d65fb72200b1455a776d38915760b097ad1fa8c1c177a8cccbff07a/tensorflow_cpu-2.3.0-cp36-cp36m-manylinux2010_x86_64.whl (137.3MB)\n",
            "\u001b[K     |████████████████████████████████| 137.3MB 87kB/s \n",
            "\u001b[?25hCollecting PyInquirer==1.0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/4c/434b7c454010a284b49d6f1d446fe8dc5960415613d8c0225b9e2efb6724/PyInquirer-1.0.3.tar.gz\n",
            "Collecting tensorflow-hub==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/00/0e/a91780d07592b1abf9c91344ce459472cc19db3b67fdf3a61dca6ebb2f5c/tensorflow_hub-0.7.0-py2.py3-none-any.whl (89kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.18.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.31.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.12.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.9.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.34.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.4.1)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Collecting prompt_toolkit==1.0.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/3d/b25d35a9f0d381dd1c02d8e04b37c353caaaff4bc32150328eeebe4931f5/prompt_toolkit-1.0.14-py3-none-any.whl (248kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 44.1MB/s \n",
            "\u001b[?25hCollecting Pygments>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/68/106af3ae51daf807e9cdcba6a90e518954eb8b70341cee52995540a53ead/Pygments-2.6.1-py3-none-any.whl (914kB)\n",
            "\u001b[K     |████████████████████████████████| 921kB 43.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex>=2016.11.21 in /usr/local/lib/python3.6/dist-packages (from PyInquirer==1.0.3->tensorflowjs) (2019.12.20)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (49.2.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.4.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt_toolkit==1.0.14->PyInquirer==1.0.3->tensorflowjs) (0.2.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-cpu<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Building wheels for collected packages: PyInquirer\n",
            "  Building wheel for PyInquirer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyInquirer: filename=PyInquirer-1.0.3-cp36-none-any.whl size=32851 sha256=992878b328393d3b371cd3ca989818b1888fd1fe2f0dfc50443201bb1ae10a46\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/6c/b1/3e4b0e8daf42a92883c7641c0ea8ffb62e0490ebed2faa55ad\n",
            "Successfully built PyInquirer\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-cpu, prompt-toolkit, Pygments, PyInquirer, tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: prompt-toolkit 1.0.18\n",
            "    Uninstalling prompt-toolkit-1.0.18:\n",
            "      Successfully uninstalled prompt-toolkit-1.0.18\n",
            "  Found existing installation: Pygments 2.1.3\n",
            "    Uninstalling Pygments-2.1.3:\n",
            "      Successfully uninstalled Pygments-2.1.3\n",
            "  Found existing installation: tensorflow-hub 0.8.0\n",
            "    Uninstalling tensorflow-hub-0.8.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.8.0\n",
            "Successfully installed PyInquirer-1.0.3 Pygments-2.6.1 prompt-toolkit-1.0.14 tensorflow-cpu-2.3.0 tensorflow-hub-0.7.0 tensorflowjs-2.3.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "prompt_toolkit",
                  "pygments",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3brVf1AGzcw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "92d2886e-f40e-4278-c93c-0ef2fae23f1d"
      },
      "source": [
        "saved_model_path = '/content/mymodel/'\n",
        "tf.saved_model.save(model, saved_model_path)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: /content/mymodel/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0L5e5ocG418",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "789bdfaf-31ac-469b-9c0d-623f9a68744d"
      },
      "source": [
        "!tensorflowjs_converter \\\n",
        "  --input_format=tf_saved_model \\\n",
        "  /content/mymodel/ \\\n",
        "  /content/modeltfjs"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-08-20 10:39:41.597567: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2020-08-20 10:39:41.601795: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2300000000 Hz\n",
            "2020-08-20 10:39:41.602035: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x30bed80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-08-20 10:39:41.602074: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-08-20 10:39:43.379334: I tensorflow/core/grappler/devices.cc:78] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
            "2020-08-20 10:39:43.379467: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\n",
            "2020-08-20 10:39:43.391372: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2020-08-20 10:39:43.391408: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: Graph size after: 251 nodes (240), 331 edges (320), time = 4.91ms.\n",
            "2020-08-20 10:39:43.391425: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   function_optimizer: function_optimizer did nothing. time = 0.06ms.\n",
            "2020-08-20 10:39:43.609375: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2020-08-20 10:39:43.609423: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   debug_stripper: debug_stripper did nothing. time = 0.013ms.\n",
            "2020-08-20 10:39:43.609440: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 147 nodes (-49), 184 edges (-49), time = 0.925ms.\n",
            "2020-08-20 10:39:43.609453: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 147 nodes (0), 184 edges (0), time = 2.421ms.\n",
            "2020-08-20 10:39:43.609465: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 147 nodes (0), 184 edges (0), time = 1.808ms.\n",
            "2020-08-20 10:39:43.609483: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 133 nodes (-14), 161 edges (-23), time = 0.967ms.\n",
            "2020-08-20 10:39:43.609524: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 133 nodes (0), 161 edges (0), time = 0.646ms.\n",
            "2020-08-20 10:39:43.609539: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 133 nodes (0), 161 edges (0), time = 2.147ms.\n",
            "2020-08-20 10:39:43.609550: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 133 nodes (0), 161 edges (0), time = 1.833ms.\n",
            "2020-08-20 10:39:43.609566: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 133 nodes (0), 161 edges (0), time = 0.859ms.\n",
            "2020-08-20 10:39:43.609582: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   debug_stripper: debug_stripper did nothing. time = 0.056ms.\n",
            "2020-08-20 10:39:43.609597: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 133 nodes (0), 161 edges (0), time = 0.526ms.\n",
            "2020-08-20 10:39:43.609613: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 133 nodes (0), 161 edges (0), time = 1.817ms.\n",
            "2020-08-20 10:39:43.609628: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 133 nodes (0), 161 edges (0), time = 1.562ms.\n",
            "2020-08-20 10:39:43.609642: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 133 nodes (0), 161 edges (0), time = 0.723ms.\n",
            "2020-08-20 10:39:43.609666: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   model_pruner: Graph size after: 133 nodes (0), 161 edges (0), time = 0.429ms.\n",
            "2020-08-20 10:39:43.609682: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 133 nodes (0), 161 edges (0), time = 1.607ms.\n",
            "2020-08-20 10:39:43.609697: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 133 nodes (0), 161 edges (0), time = 1.743ms.\n",
            "2020-08-20 10:39:43.609711: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 133 nodes (0), 161 edges (0), time = 0.731ms.\n",
            "2020-08-20 10:39:43.626300: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:816] Optimization results for grappler item: graph_to_optimize\n",
            "2020-08-20 10:39:43.626364: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   remapper: Graph size after: 130 nodes (-3), 158 edges (-3), time = 0.37ms.\n",
            "2020-08-20 10:39:43.626382: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 130 nodes (0), 158 edges (0), time = 2.182ms.\n",
            "2020-08-20 10:39:43.626394: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 130 nodes (0), 158 edges (0), time = 1.775ms.\n",
            "2020-08-20 10:39:43.626406: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 130 nodes (0), 158 edges (0), time = 0.729ms.\n",
            "2020-08-20 10:39:43.626435: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   remapper: Graph size after: 130 nodes (0), 158 edges (0), time = 0.339ms.\n",
            "2020-08-20 10:39:43.626489: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   constant_folding: Graph size after: 130 nodes (0), 158 edges (0), time = 1.625ms.\n",
            "2020-08-20 10:39:43.626505: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   arithmetic_optimizer: Graph size after: 130 nodes (0), 158 edges (0), time = 1.578ms.\n",
            "2020-08-20 10:39:43.626518: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:818]   dependency_optimizer: Graph size after: 130 nodes (0), 158 edges (0), time = 0.864ms.\n",
            "Writing weight file /content/modeltfjs/model.json...\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}